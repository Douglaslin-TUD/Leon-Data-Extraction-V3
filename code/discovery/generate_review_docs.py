#!/usr/bin/env python3
"""
Markdown Review Document Generator - Phase 3
ç”Ÿæˆäººç±»å‹å¥½çš„Markdownå®¡æ ¸æ–‡æ¡£
"""

import json
from pathlib import Path
from datetime import datetime


class ReviewDocGenerator:
    """ç”ŸæˆMarkdownå®¡æ ¸æ–‡æ¡£"""

    def __init__(self, field_mapping_file, value_mapping_file):
        # åŠ è½½æ˜ å°„æ•°æ®
        with open(field_mapping_file, 'r', encoding='utf-8') as f:
            self.field_mappings = json.load(f)

        with open(value_mapping_file, 'r', encoding='utf-8') as f:
            self.value_mappings = json.load(f)

    def generate_main_review_doc(self, output_file):
        """ç”Ÿæˆä¸»å®¡æ ¸æ–‡æ¡£"""
        content = []

        # æ ‡é¢˜
        content.append("# Contractoræ•°æ®æ˜ å°„å®¡æ ¸è¡¨")
        content.append(f"**ç”Ÿæˆæ—¥æœŸï¼š** {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        content.append(f"**å®¡æ ¸äººï¼š** Leon")
        content.append(f"**çŠ¶æ€ï¼š** â¸ï¸ å¾…å®¡æ ¸\n")
        content.append("---\n")

        # å®¡æ ¸è¯´æ˜
        content.append("## ğŸ“‹ å®¡æ ¸è¯´æ˜\n")
        content.append("### å®¡æ ¸æ ‡è®°ï¼š")
        content.append("- âœ… **æ­£ç¡®** - æ˜ å°„å…³ç³»æ­£ç¡®ï¼Œé€šè¿‡")
        content.append("- âŒ **é”™è¯¯** - æ˜ å°„å…³ç³»é”™è¯¯ï¼Œéœ€è¦ä¿®æ”¹")
        content.append("- âš ï¸ **éœ€ä¿®æ”¹** - åŸºæœ¬æ­£ç¡®ä½†éœ€è¦è°ƒæ•´\n")

        content.append("### å®¡æ ¸æ–¹æ³•ï¼š")
        content.append("1. æ£€æŸ¥æ¯ä¸ªæ˜ å°„å…³ç³»")
        content.append("2. åœ¨\"å®¡æ ¸\"åˆ—å¡«å†™ âœ…/âŒ/âš ï¸")
        content.append("3. å¦‚æœ‰é—®é¢˜ï¼Œåœ¨\"å¤‡æ³¨\"åˆ—å¡«å†™è¯´æ˜")
        content.append("4. å®Œæˆåé€šçŸ¥AIè¿›è¡Œä¸‹ä¸€æ­¥å¤„ç†\n")
        content.append("---\n")

        # å®¡æ ¸ç»Ÿè®¡
        content.append("## ğŸ“Š å®¡æ ¸ç»Ÿè®¡\n")

        total_field_mappings = len(self.field_mappings["field_mappings"])
        auto_verified_fields = sum(
            1 for field in self.field_mappings["field_mappings"].values()
            if any(c.get("verified", False) for c in field.get("contractors", {}).values())
        )

        total_value_mappings = sum(
            len(field["value_mappings"])
            for field in self.value_mappings["value_mappings"].values()
        )
        auto_verified_values = sum(
            sum(1 for m in field["value_mappings"].values() if m.get("verified", False))
            for field in self.value_mappings["value_mappings"].values()
        )
        needs_review_values = sum(
            sum(1 for m in field["value_mappings"].values() if m.get("needs_review", False))
            for field in self.value_mappings["value_mappings"].values()
        )

        content.append(f"- **å­—æ®µåæ˜ å°„æ€»æ•°ï¼š** {total_field_mappings}")
        content.append(f"  - è‡ªåŠ¨éªŒè¯ï¼ˆç½®ä¿¡åº¦â‰¥95%ï¼‰ï¼š{auto_verified_fields}")
        content.append(f"  - éœ€äººå·¥å®¡æ ¸ï¼š{total_field_mappings - auto_verified_fields}")
        content.append(f"- **å­—æ®µå€¼æ˜ å°„æ€»æ•°ï¼š** {total_value_mappings}")
        content.append(f"  - è‡ªåŠ¨éªŒè¯ï¼ˆç½®ä¿¡åº¦â‰¥95%ï¼‰ï¼š{auto_verified_values}")
        content.append(f"  - éœ€äººå·¥å®¡æ ¸ï¼ˆç½®ä¿¡åº¦<85%ï¼‰ï¼š{needs_review_values}\n")
        content.append("---\n")

        # å­—æ®µåæ˜ å°„å®¡æ ¸
        content.append("## Part 1: å­—æ®µåæ˜ å°„å®¡æ ¸\n")
        content.append("æ£€æŸ¥æ¯ä¸ªcontractorçš„å­—æ®µåæ˜¯å¦æ­£ç¡®æ˜ å°„åˆ°æ ‡å‡†å­—æ®µã€‚\n")

        for field_name in sorted(self.field_mappings["field_mappings"].keys(),
                                  key=lambda x: self.field_mappings["field_mappings"][x]["standard_field_number"]):
            field_info = self.field_mappings["field_mappings"][field_name]
            content.append(f"### å­—æ®µ {field_info['standard_field_number']}: {field_name} ({field_info['standard_field_name_cn']})\n")

            content.append("| Contractor | åŸå§‹å­—æ®µå | åˆ—ä½ç½® | ç½®ä¿¡åº¦ | æ–¹æ³• | å®¡æ ¸ | å¤‡æ³¨ |")
            content.append("|------------|-----------|--------|--------|------|------|------|")

            for contractor_id in sorted(field_info.get("contractors", {}).keys()):
                contractor_info = field_info["contractors"][contractor_id]
                confidence = contractor_info.get("confidence", 0)
                method = contractor_info.get("mapping_method", "unknown")
                verified = "âœ…" if contractor_info.get("verified", False) else "â¸ï¸"

                content.append(
                    f"| {contractor_id[:30]} | "
                    f"{contractor_info['original_field_name']} | "
                    f"{contractor_info.get('column_index', 'N/A')} | "
                    f"{confidence}% | "
                    f"{method} | "
                    f"{verified} | |"
                )

            content.append(f"\n**åŒ¹é…ç‡ï¼š** {field_info['total_matched']}/{self.field_mappings['total_contractors']} "
                           f"({field_info['match_rate']}%)\n")

        content.append("---\n")

        # å­—æ®µå€¼æ˜ å°„å®¡æ ¸
        content.append("## Part 2: å­—æ®µå€¼æ˜ å°„å®¡æ ¸\n")
        content.append("æ£€æŸ¥åŸå§‹å€¼åˆ°æ ‡å‡†å€¼çš„æ˜ å°„æ˜¯å¦æ­£ç¡®ã€‚é‡ç‚¹å…³æ³¨ âš ï¸ æ ‡è®°çš„ä½ç½®ä¿¡åº¦æ˜ å°„ã€‚\n")

        for field_name in sorted(self.value_mappings["value_mappings"].keys(),
                                  key=lambda x: self.value_mappings["value_mappings"][x]["standard_field_number"]):
            field_data = self.value_mappings["value_mappings"][field_name]

            content.append(f"### å­—æ®µ {field_data['standard_field_number']}: {field_name} ({field_data['standard_field_name_cn']})\n")

            content.append(f"**æ ‡å‡†å€¼åˆ—è¡¨ï¼š** {', '.join(field_data['standard_values'])}\n")
            content.append(f"**åŸå§‹å”¯ä¸€å€¼æ•°é‡ï¼š** {field_data['total_original_values']}\n")
            content.append(f"**å·²æ˜ å°„æ•°é‡ï¼š** {field_data['total_mapped']} ({field_data['mapping_rate']}%)\n")

            # æŒ‰ç½®ä¿¡åº¦åˆ†ç»„
            high_conf = []
            low_conf = []

            for orig_val, mapping_info in sorted(field_data["value_mappings"].items()):
                if mapping_info.get("needs_review", False):
                    low_conf.append((orig_val, mapping_info))
                else:
                    high_conf.append((orig_val, mapping_info))

            # å…ˆæ˜¾ç¤ºéœ€è¦å®¡æ ¸çš„ï¼ˆä½ç½®ä¿¡åº¦ï¼‰
            if low_conf:
                content.append(f"\n#### âš ï¸ éœ€è¦å®¡æ ¸çš„æ˜ å°„ ({len(low_conf)}ä¸ª)\n")
                content.append("| åŸå§‹å€¼ | å»ºè®®æ ‡å‡†å€¼ | ç½®ä¿¡åº¦ | æ¨ç†æ–¹æ³• | æ¨ç†è¯´æ˜ | å®¡æ ¸ | Leonå¤‡æ³¨ |")
                content.append("|--------|-----------|--------|---------|---------|------|----------|")

                for orig_val, mapping_info in low_conf:
                    content.append(
                        f"| `{orig_val}` | "
                        f"`{mapping_info['standard_value']}` | "
                        f"{mapping_info['confidence']:.2f} | "
                        f"{mapping_info['mapping_method']} | "
                        f"{mapping_info['reasoning']} | "
                        f"â¸ï¸ | |"
                    )

            # é«˜ç½®ä¿¡åº¦æ˜ å°„ï¼ˆæŠ˜å æ˜¾ç¤ºï¼‰
            if high_conf:
                content.append(f"\n<details>")
                content.append(f"<summary>âœ… é«˜ç½®ä¿¡åº¦æ˜ å°„ ({len(high_conf)}ä¸ª) - ç‚¹å‡»å±•å¼€</summary>\n")
                content.append("| åŸå§‹å€¼ | æ ‡å‡†å€¼ | ç½®ä¿¡åº¦ | æ–¹æ³• | è¯´æ˜ |")
                content.append("|--------|--------|--------|------|------|")

                for orig_val, mapping_info in high_conf[:50]:  # åªæ˜¾ç¤ºå‰50ä¸ª
                    content.append(
                        f"| `{orig_val}` | "
                        f"`{mapping_info['standard_value']}` | "
                        f"{mapping_info['confidence']:.2f} | "
                        f"{mapping_info['mapping_method']} | "
                        f"{mapping_info['reasoning']} |"
                    )

                if len(high_conf) > 50:
                    content.append(f"\n*ï¼ˆè¿˜æœ‰ {len(high_conf) - 50} ä¸ªé«˜ç½®ä¿¡åº¦æ˜ å°„æœªæ˜¾ç¤ºï¼‰*")

                content.append("</details>\n")

        content.append("---\n")

        # å®¡æ ¸å®Œæˆç¡®è®¤
        content.append("## âœ… å®¡æ ¸å®Œæˆç¡®è®¤\n")
        content.append("è¯·åœ¨å®Œæˆå®¡æ ¸åå¡«å†™ï¼š\n")
        content.append("- [ ] Part 1 å­—æ®µåæ˜ å°„å®¡æ ¸å®Œæˆ")
        content.append("- [ ] Part 2 å­—æ®µå€¼æ˜ å°„å®¡æ ¸å®Œæˆ")
        content.append("- [ ] æ‰€æœ‰é—®é¢˜å·²æ ‡è®°å’Œè¯´æ˜\n")
        content.append(f"**å®¡æ ¸å®Œæˆæ—¥æœŸï¼š** ___________\n")
        content.append(f"**å®¡æ ¸äººç­¾åï¼š** ___________\n")

        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content))

        print(f"âœ… ä¸»å®¡æ ¸æ–‡æ¡£å·²ç”Ÿæˆ: {output_file}")
        return output_file

    def generate_field_specific_docs(self, output_dir):
        """ä¸ºæ¯ä¸ªå­—æ®µç”Ÿæˆç‹¬ç«‹çš„å®¡æ ¸æ–‡æ¡£"""
        field_dir = output_dir / "02_Value_Mappings"
        field_dir.mkdir(parents=True, exist_ok=True)

        generated_files = []

        for field_name, field_data in self.value_mappings["value_mappings"].items():
            content = []

            content.append(f"# {field_name} - å­—æ®µå€¼æ˜ å°„å®¡æ ¸\n")
            content.append(f"**æ ‡å‡†å­—æ®µç¼–å·ï¼š** {field_data['standard_field_number']}")
            content.append(f"**ä¸­æ–‡åç§°ï¼š** {field_data['standard_field_name_cn']}")
            content.append(f"**æ ‡å‡†å®šä¹‰ï¼š** è§ [Template_2022_Complete_Field_Reference.md](../../Template_2022_Complete_Field_Reference.md)\n")
            content.append("---\n")

            content.append("## æ ‡å‡†å€¼åˆ—è¡¨\n")
            for std_val in field_data["standard_values"]:
                content.append(f"- `{std_val}`")
            content.append("")

            content.append("## åŸå§‹å€¼æ˜ å°„è¡¨\n")
            content.append("| åŸå§‹å€¼ | â†’ | æ ‡å‡†å€¼ | ç½®ä¿¡åº¦ | æ¨ç†æ–¹æ³• | æ¨ç†è¯´æ˜ | å®¡æ ¸ | Leonå¤‡æ³¨ |")
            content.append("|--------|---|--------|--------|---------|---------|------|----------|")

            for orig_val in sorted(field_data["value_mappings"].keys()):
                mapping_info = field_data["value_mappings"][orig_val]
                verified_mark = "âœ…" if mapping_info.get("verified", False) else "â¸ï¸"
                if mapping_info.get("needs_review", False):
                    verified_mark = "âš ï¸"

                content.append(
                    f"| `{orig_val}` | â†’ | "
                    f"`{mapping_info['standard_value']}` | "
                    f"{mapping_info['confidence']:.2f} | "
                    f"{mapping_info['mapping_method']} | "
                    f"{mapping_info['reasoning']} | "
                    f"{verified_mark} | |"
                )

            # å†™å…¥æ–‡ä»¶
            filename = field_dir / f"{field_name}_value_mappings.md"
            with open(filename, 'w', encoding='utf-8') as f:
                f.write('\n'.join(content))

            generated_files.append(filename)
            print(f"  âœ… ç”Ÿæˆ: {filename.name}")

        return generated_files

    def generate_overview_doc(self, output_dir):
        """ç”Ÿæˆæ˜ å°„æ¦‚è¿°æ–‡æ¡£"""
        content = []

        content.append("# Contractoræ•°æ®æ˜ å°„æ¦‚è¿°\n")
        content.append(f"**ç”Ÿæˆæ—¥æœŸï¼š** {datetime.now().strftime('%Y-%m-%d')}")
        content.append(f"**é¡¹ç›®ï¼š** Leon Data Extraction - Contractoræ•°æ®æ ‡å‡†åŒ–")
        content.append(f"**é˜¶æ®µï¼š** Phase 1-2 å®Œæˆï¼ŒPhase 3 å¾…å®¡æ ¸\n")
        content.append("---\n")

        content.append("## ğŸ“Š æ€»ä½“ç»Ÿè®¡\n")
        content.append(f"- **æ‰«ææ–‡ä»¶æ•°ï¼š** {self.field_mappings['total_contractors']}")
        content.append(f"- **å…³é”®å­—æ®µæ•°ï¼š** 15")
        content.append(f"- **å·²æ˜ å°„å­—æ®µï¼š** {len(self.field_mappings['field_mappings'])}")
        content.append(f"- **æ€»å€¼æ˜ å°„æ•°ï¼š** {sum(len(f['value_mappings']) for f in self.value_mappings['value_mappings'].values())}\n")

        content.append("## ğŸ“ æ–‡æ¡£ç»“æ„\n")
        content.append("```")
        content.append("Contractor_Mapping_Documentation/")
        content.append("â”œâ”€â”€ 00_Contractor_Mapping_Overview.md          # æœ¬æ–‡æ¡£")
        content.append("â”œâ”€â”€ 01_Contractor_Mapping_Review.md            # ä¸»å®¡æ ¸æ–‡æ¡£ï¼ˆâ¸ï¸ å¾…å®¡æ ¸ï¼‰")
        content.append("â””â”€â”€ 02_Value_Mappings/                         # å­—æ®µå€¼æ˜ å°„ï¼ˆæŒ‰å­—æ®µåˆ†æ–‡ä»¶ï¼‰")
        for field_name in sorted(self.value_mappings["value_mappings"].keys()):
            content.append(f"    â”œâ”€â”€ {field_name}_value_mappings.md")
        content.append("```\n")

        content.append("## ğŸ” å­—æ®µæ˜ å°„æ¦‚è§ˆ\n")
        content.append("| # | å­—æ®µå | ä¸­æ–‡å | åŒ¹é…ç‡ | çŠ¶æ€ |")
        content.append("|---|--------|--------|--------|------|")

        for field_name in sorted(self.field_mappings["field_mappings"].keys(),
                                  key=lambda x: self.field_mappings["field_mappings"][x]["standard_field_number"]):
            field_info = self.field_mappings["field_mappings"][field_name]
            status = "âœ…" if field_info["match_rate"] >= 90 else "âš ï¸"

            content.append(
                f"| {field_info['standard_field_number']} | "
                f"{field_name} | "
                f"{field_info['standard_field_name_cn']} | "
                f"{field_info['match_rate']}% | "
                f"{status} |"
            )

        content.append("\n## ğŸ“ ä¸‹ä¸€æ­¥è¡ŒåŠ¨\n")
        content.append("1. â¸ï¸ Leonå®¡æ ¸ `01_Contractor_Mapping_Review.md`")
        content.append("2. â¸ï¸ æ ‡è®°æ‰€æœ‰æ˜ å°„å…³ç³»ï¼ˆâœ…/âŒ/âš ï¸ï¼‰")
        content.append("3. â¸ï¸ å¡«å†™å¤‡æ³¨è¯´æ˜")
        content.append("4. â¸ï¸ é€šçŸ¥AIè¿›è¡ŒPhase 4ï¼ˆé…ç½®ä¿å­˜ï¼‰\n")

        # å†™å…¥æ–‡ä»¶
        filename = output_dir / "00_Contractor_Mapping_Overview.md"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content))

        print(f"âœ… æ¦‚è¿°æ–‡æ¡£å·²ç”Ÿæˆ: {filename}")
        return filename


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("Markdownå®¡æ ¸æ–‡æ¡£ç”Ÿæˆå™¨ - Phase 3")
    print("=" * 80)

    # è®¾ç½®è·¯å¾„
    base_dir = Path("/data/AI Life/Work/RWS_Road_Engineer/01-Projects/Leon_Data_Extraction/Analysis")
    input_dir = base_dir / "Contractor_Discovery"
    output_dir = base_dir / "Contractor_Mapping_Documentation"

    field_mapping_file = input_dir / "contractor_field_name_mapping.json"
    value_mapping_file = input_dir / "contractor_value_mapping.json"

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)

    # åˆ›å»ºç”Ÿæˆå™¨
    generator = ReviewDocGenerator(field_mapping_file, value_mapping_file)

    # ç”Ÿæˆæ–‡æ¡£
    print("\nç”Ÿæˆæ–‡æ¡£...")

    # 1. æ¦‚è¿°æ–‡æ¡£
    generator.generate_overview_doc(output_dir)

    # 2. ä¸»å®¡æ ¸æ–‡æ¡£
    main_review_file = output_dir / "01_Contractor_Mapping_Review.md"
    generator.generate_main_review_doc(main_review_file)

    # 3. å­—æ®µç‰¹å®šæ–‡æ¡£
    print("\nç”Ÿæˆå­—æ®µç‰¹å®šæ–‡æ¡£:")
    generator.generate_field_specific_docs(output_dir)

    print("\n" + "=" * 80)
    print("âœ… Phase 3 å®Œæˆï¼")
    print("=" * 80)
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"\nğŸ“„ ç”Ÿæˆçš„æ–‡æ¡£:")
    print(f"   1. 00_Contractor_Mapping_Overview.md      - æ˜ å°„æ¦‚è¿°")
    print(f"   2. 01_Contractor_Mapping_Review.md        - ä¸»å®¡æ ¸æ–‡æ¡£ï¼ˆâ¸ï¸ å¾…Leonå®¡æ ¸ï¼‰")
    print(f"   3. 02_Value_Mappings/                     - å­—æ®µå€¼æ˜ å°„è¯¦æƒ…\n")

    print("ğŸ¯ ä¸‹ä¸€æ­¥ï¼šLeonå®¡æ ¸ 01_Contractor_Mapping_Review.md")
    print("   å¡«å†™å®¡æ ¸æ ‡è®°: âœ…æ­£ç¡® / âŒé”™è¯¯ / âš ï¸éœ€ä¿®æ”¹")


if __name__ == "__main__":
    main()
